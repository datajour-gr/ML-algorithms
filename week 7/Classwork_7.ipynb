{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwork 7 - Τυχαίο Δάσος\n",
    "\n",
    "Σήμερα θα δούμε στην πράξη πως λειτουργούν τα τυχαία δάση.\n",
    "\n",
    "\n",
    "Περισσότερα:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Βασική ροή εργασιών με τα σπίτια στη Βοστώνη.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston_set = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# φτιάχνουμε το dataframe \n",
    "boston_df = pd.DataFrame(boston_set.data, columns=boston_set.feature_names)\n",
    "\n",
    "# προσθέτουμε την τιμή των σπιτιών\n",
    "boston_df['PRICE'] = pd.Series(boston_set.target)  \n",
    "\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#δουλέυουμε με τα missing values \n",
    "boston_df.isnull().sum() \n",
    "\n",
    "\n",
    "missing_values = [\"n/a\", \"na\", \"--\", 999,9999]   \n",
    "\n",
    "# αλλάζουμε τις τιμές στο υπάρχον dataframe, γιαυτό βάζουμε inplace = True\n",
    "boston_df.replace(to_replace = missing_values, value = np.nan, inplace = True) \n",
    "# πετάμε τα NaNs \n",
    "boston_df.dropna(inplace=True) \n",
    "# Reindex το dataframe. Αφού πετάξουμε τα missing values, το index δεν ταιριάζει πλέον γιατί λείπουν γραμμές\n",
    "boston_df.reset_index(drop=True, inplace=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train - test split\n",
    "\n",
    "### Προτετοιμασία δεδομένων\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "boston_train, boston_test = train_test_split(boston_df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Βάζουμε όλα τα features στο X_train και βγάζουμε το PRICE γιατί είναι το target\n",
    "X_train = boston_train.drop(columns='PRICE')\n",
    "# Το target 'price' στο y_train\n",
    "y_train = boston_train['PRICE']\n",
    "\n",
    "# Βάζουμε όλα τα features στο X_train και βγάζουμε το PRICE γιατί είναι το target\n",
    "X_test = boston_test.drop(columns = 'PRICE')\n",
    "# Το target 'price' στο y_train\n",
    "y_test = boston_test['PRICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Επανάληψη  Δέντρο αποφάσεων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# εισάγουμε το decision tree\n",
    "dec_tree = DecisionTreeRegressor()\n",
    "# εκπαίδευση DecisionTreeRegressor\n",
    "dec_tree.fit(X_train, y_train)     \n",
    "# υπολογισμός των predictions του TEST data-set \n",
    "y_pred_test_dec_tree = dec_tree.predict(X_test) \n",
    "# υπολογισμός των λαθών\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test_dec_tree)) \n",
    "\n",
    "r2 = round(dec_tree.score(X_test, y_test), 2)  \n",
    "\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('RMSE is {}'.format(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "s1 = plt.scatter(y_test, y_pred_test_dec_tree, color='darkgreen',\n",
    "                 marker='o', alpha = 0.3, label = 'decision tree')\n",
    "# labels\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "# title\n",
    "plt.title('Testing data performance')\n",
    "# legend με τα labels \n",
    "plt.legend()\n",
    "# τελικό plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Τυχαίο Δάσος (Random forest)\n",
    "\n",
    "Η διαδικασία είναι η ίδια το μόνο που αλλάζει πρακτικά είναι ότι πρέπει να αντικαταστήσουμε το DecisionTreeRegressor() με το RandomForestRegressor(). \n",
    "Φυσικά όπως και με τα δέντρα αποφάσεων πρέπει να σκεφτούμε και τις παραμέτρους που βελτιώνουν την πρόβλεψη. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# εισάγουμε το Random forest\n",
    "rf_regr = RandomForestRegressor(n_estimators=100) # n_estimators is the first important hyperparameter it is the number of trees in the forest, the more trees the better, but slows down the computation\n",
    "# Fitting των δέντρων\n",
    "rf_regr.fit(X_train, y_train)\n",
    "# Predicting στα testing data\n",
    "y_pred_test = rf_regr.predict(X_test)\n",
    "# υπολογισμός του root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test)) \n",
    "# υπολογισμός του r squared\n",
    "r2 = round(rf_regr.score(X_test, y_test), 2)  \n",
    "\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('RMSE is {}'.format(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "#s1 = plt.scatter(y_test, y_pred_test_dec_tree,color='darkblue', marker='o', alpha = 0.3, label = 'decision tree')\n",
    "s2 = plt.scatter(y_test, y_pred_test, color='red', \n",
    "                 marker='o', alpha = 0.3, label = 'random forest')\n",
    "# labels\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "# title\n",
    "plt.title('Testing data performance')\n",
    "# legend \n",
    "plt.legend()\n",
    "# final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κάντε comment/uncomment τα Scatterplots (s1 & s2) για να συγκρίνετε το Decision tree και το Random Forest. \n",
    "Παρατηρούμε ότι οι προβλεπόμενες τιμές τυπώνονται σε σχέση με τις πραγματικές.\n",
    "Όσο λιγότερος θόρυβος στο data cloud, τόσο καλύτερα τα predictions. \n",
    "Μια ίσια γραμμή θα ανταποκρινόταν στην τέλεια πρόβλεψη. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Περίληψη \n",
    "\n",
    "Βλέπουμε ότι το τυχαίο δάσος αποδίδει το ίδιο καλά, ενδεχομένως και λίγο καλύτερα από ένα μεμονωμένο δέντρο. \n",
    "\n",
    "Ας προχωρήσουμε και να κάνουμε την ίδια σύγκριση μεταξύ Decision Trees  και Random forests σε ένα k-fold cross validation. \n",
    "Το πλεονέκτημα είναι ότι μπορούμε να αξιολογήσουμε την απόδοσή τους σε πολλούς διαφορετικούς διαχωρισμούς δεδομένων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ροή εργασιών με cross-validation \n",
    "## 2.1 Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_df.drop(columns = 'PRICE')\n",
    "y = boston_df['PRICE']\n",
    "r2_scores = []\n",
    "ls_true_values = []\n",
    "ls_predicted_values = []\n",
    "# Cross-Validation (cv)\n",
    "our_cv = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "# Λούπα στα splits \n",
    "for i_train, i_test in our_cv.split(X):\n",
    "    # training και test set σύμφωνα με το τρέχον split\n",
    "    X_train, X_test, y_train, y_test = X.iloc[i_train], X.iloc[i_test], y.iloc[i_train], y.iloc[i_test]\n",
    "    # decision tree\n",
    "    dec_tree = DecisionTreeRegressor()\n",
    "    # Fitting \n",
    "    dec_tree.fit(X_train, y_train)\n",
    "    # Predicting \n",
    "    y_pred_test = dec_tree.predict(X_test)\n",
    "    # R2 score\n",
    "    r2 = round(dec_tree.score(X_test, y_test), 2)\n",
    "    # Append score στην άδεια λίστα που ορίσαμε επάνω R2 scores\n",
    "    r2_scores.append(r2)\n",
    "    ls_true_values.append(y_test)\n",
    "    ls_predicted_values.append(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1\n",
    "#mean και standard deviation\n",
    "mean_r2 = round(np.mean(r2_scores),2)\n",
    "std_r2 = round(np.std(r2_scores),2)\n",
    "print('Mean of r2 scores: {} \\nStandard deviation of r2 scores: {}'\n",
    "      .format(mean_r2, std_r2))\n",
    "# Οπτικοποίηση ακρίβειας των διαφορετικών τυχαίων διαιρέσεων\n",
    "plt.plot(r2_scores, marker='o', linestyle='None')\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.title('Accuracy of single repetitions in cross-validation')\n",
    "plt.xlabel('different random data splits')\n",
    "plt.ylabel('r2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2\n",
    "# Concatenate data για το plotting\n",
    "ls_predicted_values = np.concatenate(ls_predicted_values)\n",
    "ls_true_values = np.concatenate(ls_true_values)\n",
    "# scatter plot\n",
    "s1 = plt.scatter(ls_predicted_values, ls_true_values, color='darkblue', marker='o', alpha = 0.1, label = 'true vs predicted values')\n",
    "# labels\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "# title\n",
    "plt.title('Testing data performance - Decision tree')\n",
    "# legend \n",
    "plt.legend()\n",
    "# final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Θα εκπαιδεύσουμε 100 RandomForests το καθένα από 100 trees οπότε 10000 trees στο σύνολο, οπότε διαρκεί παραπάνω\n",
    "X = boston_df.drop(columns = 'PRICE')\n",
    "y = boston_df['PRICE']\n",
    "r2_scores = []\n",
    "ls_true_values = [] # άδειες λίστες στις οποίες θα προστεθούν τιμές στην συνέχεια\n",
    "ls_predicted_values = []\n",
    "# Cross-Validation (cv)\n",
    "our_cv = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "\n",
    "for i_train, i_test in our_cv.split(X):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.iloc[i_train], X.iloc[i_test], y.iloc[i_train], y.iloc[i_test]\n",
    "    # decision tree\n",
    "    rf_regr = RandomForestRegressor(n_estimators=100)\n",
    "    # Fitting \n",
    "    rf_regr.fit(X_train, y_train)\n",
    "    # Predicting \n",
    "    y_pred_test = rf_regr.predict(X_test)\n",
    "    # R2 score\n",
    "    r2 = round(rf_regr.score(X_test, y_test), 2)\n",
    "    # Append score \n",
    "    r2_scores.append(r2) # εδώ προσθέτονται οι τιμές για τις λίστες που υπάρχουν επάνω\n",
    "    ls_true_values.append(y_test)\n",
    "    ls_predicted_values.append(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1\n",
    "#Calculating mean και standard deviation\n",
    "mean_r2 = round(np.mean(r2_scores),2)\n",
    "std_r2 = round(np.std(r2_scores),2)\n",
    "print('Mean of r2 scores: {} \\nStandard deviation of r2 scores: {}'\n",
    "      .format(mean_r2, std_r2))\n",
    "# Οπτικοποίηση ακρίβειας των διαφορετικών τυχαίων διαιρέσεων\n",
    "plt.plot(r2_scores, marker='o', linestyle='None')\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.title('Accuracy of single repetitions in cross-validation')\n",
    "plt.xlabel('different random data splits')\n",
    "plt.ylabel('r2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2\n",
    "# Concatenate data για το plotting\n",
    "ls_predicted_values = np.concatenate(ls_predicted_values)\n",
    "ls_true_values = np.concatenate(ls_true_values)\n",
    "# scatter plot\n",
    "s1 = plt.scatter(ls_predicted_values, ls_true_values, color='darkblue', \n",
    "                 marker='o', alpha = 0.1, label = 'true vs predicted values')\n",
    "# labels\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "# title\n",
    "plt.title('Testing data performance - Random forest')\n",
    "# legend \n",
    "plt.legend()\n",
    "# final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό είναι αξιοθαύμαστο! Η μέθοδος RandomForest πέτυχε πολύ υψηλότερη μέση ακρίβεια πρόβλεψης (που μετριέται σε R²) και επίσης μια χαμηλότερη μεταβλητότητα και ως εκ τούτου, τα αποτελέσματα είναι σταθερότερα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Βελτιστοποίηση τυχαίου δάσους - ας δούμε πόσο μακριά μπορούμε να το φτάσουμε\n",
    "\n",
    "Μπορεί να πάρει λίγο χρόνο για τον υπολογισμό, ανάλογα με τα διαφορετικά βάθη "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Πάμε να βελτιστοποιήσουμε ορισμένες παραμέτρους\n",
    "X = boston_df.drop(columns = 'PRICE')\n",
    "y = boston_df['PRICE']\n",
    "# άδειες λίστες\n",
    "ls_total_r2_test = []\n",
    "ls_total_r2_train = []\n",
    "# λίστα για βάθος\n",
    "ls_max_depth = []\n",
    "# Λούπα στα βάθη των δέντρων του RandomForest από το 1 μέχρι το 10, τα βάθη μπορείτε να τα αλλάξετε\n",
    "for current_max_depth in np.arange(10): \n",
    "    # ξεκινάει το επαναλαμβανόμενο cross validation (cv) \n",
    "    our_cv = RepeatedKFold(n_splits=10, n_repeats=10)\n",
    "    #  RandomForests regressor και ορίζουμε το max depth του κάθε single tree\n",
    "    rf_regr = RandomForestRegressor(max_depth=current_max_depth+1, n_estimators=100)\n",
    "    # άδεια λίστα των single cv loop results\n",
    "    ls_r2_test = []\n",
    "    ls_r2_train = []\n",
    "    # Λούπα του cross validation\n",
    "    for i_train, i_test in our_cv.split(X):\n",
    "        # 1. Split data \n",
    "        X_train, X_test, y_train, y_test = X.iloc[i_train], X.iloc[i_test], y.iloc[i_train], y.iloc[i_test]\n",
    "        # 2. Train DT regressor \n",
    "        rf_regr.fit(X_train, y_train)\n",
    "        # 3. Test regressor με τα test data\n",
    "        y_pred_test = rf_regr.predict(X_test)\n",
    "        y_pred_train = rf_regr.predict(X_train)\n",
    "        # 4. υπολογισμός λαθών\n",
    "        current_r2_test = r2_score(y_test, y_pred_test)\n",
    "        current_r2_train = r2_score(y_train, y_pred_train)\n",
    "        # 5. Append \n",
    "        ls_r2_test.append(current_r2_test)\n",
    "        ls_r2_train.append(current_r2_train)\n",
    "        #τέλος: πρέπει να υπάρχουν 100 τιμές - 10 subsets *10 repeats\n",
    "    # 6. append max depth\n",
    "    ls_max_depth.append(current_max_depth+1)\n",
    "    # append mean of 100 r2 στη λίστα\n",
    "    ls_total_r2_test.append(np.mean(ls_r2_test))  \n",
    "    ls_total_r2_train.append(np.mean(ls_r2_train))  \n",
    "# οπτικοποίηση του R2 ανά βάθος\n",
    "plt.plot(ls_max_depth, ls_total_r2_train, label=\"Training data\")\n",
    "plt.plot(ls_max_depth, ls_total_r2_test, label=\"Testing data\")\n",
    "plt.xticks(np.arange(10)+1)\n",
    "plt.xlabel('tree depth')\n",
    "plt.ylabel('R²')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# best depth\n",
    "print('Best performance: {}\\nBest depth: {}'.format(max(ls_total_r2_test), np.argmax(ls_total_r2_test)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα που γνωρίζουμε το βέλτιστο βάθος πάμε πίσω στο κεφάλαιο 2.2 RandomForest και εισάγουμε αυτήν την υπερ-παράμετρο (hyper-parameter).\n",
    "Προσθέστε το ως παράμετρο όταν δημιουργείτε το Random Forest στη λούπα του cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Συμπέρασμα\n",
    "\n",
    "Τα αποτελέσματα δείχνουν, ότι τόσο στο train-test split καθώς και στη ροή εργασίας του cross-validation, η μέθοδος Random Forest παρουσιάζει βελτιωμένη απόδοση σε σχέση με τα μεμονωμένα δέντρα αποφάσεων όσον αφορά την πρόβλεψη. Εμφανίζει σταθερά υψηλότερες τιμές R². \n",
    "\n",
    "Μια άλλη ενδιαφέρουσα πτυχή είναι η απόδοση των Random Forests στα διαφορετικά βάθη δέντρων. Τα δέντρα απόφασεων μειώνονται στην απόδοση εάν η πολυπλοκότητά τους (βάθος δέντρων) είναι πάρα πολύ υψηλή, δεδομένου ότι υπερταιριάζουν (κάνουν overfit) τα στοιχεία εκπαίδευσης. Αντίθετα, τα RandomForests είναι σε θέση να αντιμετωπίζουν πιο ήπια αυτό το πρόβλημα μέσω του μέσου όρου των πολλών δέντρων που υπολογίζουν, ακόμη και όταν τα δέντρα έχουν υψηλό βάθος. Σε αυτό το παράδειγμα, το υψηλότερο βάθος δεν μειώνει υπερβολικά τις επιδόσεις. Ωστόσο, αυτό ΔΕΝ σημαίνει ότι η μέθοδος RandomForest δεν επηρεάζεται από το overfitting, είναι απλά πιο ανθεκτική σε αυτό το πρόβλημα. Σε επόμενα παραδείγματα θα είναι απαραίτητο να ορίζετε τις υπερπαραμέτρους του RandomForest, π.χ. το βάθος του μεμονωμένου δέντρου.\n",
    "\n",
    "Ένα σημαντικό μειονέκτημα που έχουν τα RandomForests είναι οι υπολογιστικές δαπάνες τους. Η πρόβλεψη σε μεγάλα σύνολα δεδομένων, συμπεριλαμβανομένης της βελτιστοποίησης των υπερπαραμέτρων, μπορεί να διαρκέσει μέρες."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συγχαρητήρια που έφτασες ως εδώ!\n",
    "\n",
    "Τώρα που είστε εξοπλισμένοι με νέα εργαλεία, θα δουλέψετε με το έτοιμο σύνολο δεδομένων diabetes \n",
    "για να δείτε μέχρι που μπορείτε να φτάσετε!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Homework 7\n",
    "\n",
    "Προβλέψτε την εξέλιξη του διαβήτη χρησιμοποιώντας Random Forests σε μια ροή εργασιών με cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes data set - Συγκρίνετε την πρόβλεψη ενός δέντρου αποφάσεων και ενός τυχαίου δάσους με χρήση cross validation\n",
    "from sklearn import datasets \n",
    "diabetes_set = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Οργανώστε τα δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Καθαρίστε τα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εκπαιδεύστε ένα decision tree και μετά ένα random forest σε μια ροή εργασιών με cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Γράψτε μια παράγραφο με τα συμπεράσματά σας"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
